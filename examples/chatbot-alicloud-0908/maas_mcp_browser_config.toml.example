# MaaS Client Configuration with Browser Automation
# Voice-enabled web browsing and information extraction
# Supports both OpenAI and Alibaba Cloud models

default_model = "qwen-max"
system_prompt = """你是一个智能助手，可以浏览网页、获取信息、截图和自动化网页操作。
当用户询问网页内容或需要从网站获取信息时，使用浏览器工具帮助他们。
当用户询问天气时，使用可用的工具获取准确的天气数据。
用自然、对话式的语气回答。。

You are an intelligent assistant that can browse websites, extract information, take screenshots, and automate web interactions.
When users ask about web content or need information from websites, use browser tools to help them.
You can also check weather information. Respond in a natural, conversational tone.
Answer in the language the user speaks."""

max_history_exchanges = 30
enable_streaming = true
log_level = "INFO"

# Enable MCP tools
enable_tools = true

# Alibaba Cloud Provider (Primary)
[[providers]]
id = "alicloud"
kind = "alicloud"
api_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
api_key = "env:ALIBABA_CLOUD_API_KEY"  # Use environment variable for security
proxy = false

# OpenAI Provider (Secondary)
[[providers]]
id = "openai"
kind = "openai"
api_key = "env:OPENAI_API_KEY"  # Use environment variable for security
api_url = "https://api.openai.com/v1"
proxy = false

# ============================================
# Alibaba Cloud Models
# ============================================

# Qwen Series - Main models
[[models]]
id = "qwen-max"
route = { provider = "alicloud", model = "qwen-max" }

[[models]]
id = "qwen-plus"
route = { provider = "alicloud", model = "qwen-plus" }

[[models]]
id = "qwen-turbo"
route = { provider = "alicloud", model = "qwen-turbo" }

[[models]]
id = "qwen-long"
route = { provider = "alicloud", model = "qwen-long" }

# Qwen Vision-Language Models
[[models]]
id = "qwen-vl-max"
route = { provider = "alicloud", model = "qwen-vl-max" }

[[models]]
id = "qwen-vl-plus"
route = { provider = "alicloud", model = "qwen-vl-plus" }

# Qwen Coder Models
[[models]]
id = "qwen-coder-turbo"
route = { provider = "alicloud", model = "qwen-coder-turbo" }

[[models]]
id = "qwen-coder-plus"
route = { provider = "alicloud", model = "qwen-coder-plus" }

# DeepSeek Models
[[models]]
id = "deepseek-v3"
route = { provider = "alicloud", model = "deepseek-v3" }

[[models]]
id = "deepseek-v3.1"
route = { provider = "alicloud", model = "deepseek-v3.1" }

[[models]]
id = "deepseek-r1-0528"
route = { provider = "alicloud", model = "deepseek-r1-0528" }

# GLM Model
[[models]]
id = "glm-4.5"
route = { provider = "alicloud", model = "glm-4.5" }

# Kimi Model
[[models]]
id = "Moonshot-Kimi-K2-Instruct"
route = { provider = "alicloud", model = "Moonshot-Kimi-K2-Instruct" }

# ============================================
# OpenAI Models (for fallback/comparison)
# ============================================
[[models]]
id = "gpt-4o-mini"
route = { provider = "openai", model = "gpt-4o-mini" }

[[models]]
id = "gpt-4o"
route = { provider = "openai", model = "gpt-4o" }

# Playwright MCP Server for browser automation
[[mcp.servers]]
name = "playwright"
protocol = "stdio"  
command = "npx"
args = [
    "-y",
    "@playwright/mcp@latest"
]

# Mock Weather Server
[[mcp.servers]]
name = "mock-weather"
protocol = "stdio"
command = "python3"
args = ["mock_weather_server.py"]

# Filesystem for saving screenshots and data
[[mcp.servers]]
name = "filesystem"
protocol = "stdio"
command = "npx"
args = [
    "-y",
    "@modelcontextprotocol/server-filesystem",
    "/tmp/browser-data"
]
