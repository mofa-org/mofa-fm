nodes:
  - id: wserver
    path: dynamic
    inputs:
      audio: kokoro-tts/audio
      asr_transcription: asr/transcription
      asr_log: asr/log
      speech_log: speech-monitor/log
      speech_started: speech-monitor/speech_started
      speech_ended: speech-monitor/speech_ended
      question_ended: speech-monitor/question_ended
      segment_complete: kokoro-tts/segment_complete
      tts_log: kokoro-tts/log
    outputs:
      - audio
      - text

  # Speech detection and segmentation with pause/resume capability
  - id: speech-monitor
    build: pip install -e ../../node-hub/dora-speechmonitor
    path: dora-speechmonitor
    inputs:
      audio:
        source: wserver/audio
        queue_size: 1000000
    outputs:
      - speech_started
      - speech_ended
      - question_ended
      - is_speaking
      - audio_segment
      - speech_probability
      - log
    env:
      MIN_AUDIO_AMPLITUDE: 0.005
      ACTIVE_FRAME_THRESHOLD_MS: 60
      USER_SILENCE_THRESHOLD_MS: 1200  # Faster turn end
      SILENCE_THRESHOLD_MS: 400
      QUESTION_END_SILENCE_MS: 1500
      AUDIO_FRAMES_THRESHOLD_MS: 10000
      VAD_THRESHOLD: 0.5
      VAD_ENABLED: true
      SAMPLE_RATE: 16000
      LOG_LEVEL: DEBUG


  # ASR transcription
  - id: asr
    build: pip install -e ../../node-hub/dora-asr
    path: dora-asr
    inputs:
      audio:
        source: speech-monitor/audio_segment
        queue_size: 10
    outputs:
      - transcription
      - language_detected
      - processing_time
      - confidence
      - log
    env:
      ASR_ENGINE: funasr
      LANGUAGE: zh
      WHISPER_MODEL: large
      ENABLE_PUNCTUATION: true
      ENABLE_LANGUAGE_DETECTION: true
      ENABLE_CONFIDENCE_SCORE: false
      ASR_MODELS_DIR: $HOME/.dora/models/asr # Relative path (recommended)
      LOG_LEVEL: INFO


  # MaaS Client with Playwright Browser Tools (now static to allow reuse)
  - id: maas-client
    # Run as a static node using the prebuilt binary included in the image
    path: ../../target/release/dora-maas-client
    inputs:
      text: asr/transcription  # Direct from ASR
      text_to_audio: wserver/text  # Also receive text from WebSocket for greetings
    outputs:
      - text
      - status
      - log
    env:
      # Use the same config file mounted by docker compose
      MAAS_CONFIG_PATH: maas_mcp_browser_config_zh.local.toml
      LOG_LEVEL: INFO

  # Text Segmenter - buffers LLM output and sends to TTS one segment at a time
  - id: text-segmenter
    build: pip install -e ../../node-hub/dora-text-segmenter
    path: dora-text-segmenter
    inputs:
      text: maas-client/text  # From MaaS
      tts_complete: kokoro-tts/segment_complete  # TTS completion signal
    outputs:
      - text_segment_text  # Dynamic output with participant suffix
      - status
      - metrics
    env:
      ENABLE_BACKPRESSURE: "false"  # Don't wait initially - send first segment immediately
      SEGMENT_MODE: "sentence"  # sentence, punctuation, or fixed
      MIN_SEGMENT_LENGTH: "5"
      MAX_SEGMENT_LENGTH: "20"
      PUNCTUATION_MARKS: "。！？.!?"
      LOG_LEVEL: "DEBUG"

  # Kokoro TTS - Fast multi-language TTS (drop-in replacement for PrimeSpeech)
  - id: kokoro-tts
    build: pip install -e ../../node-hub/dora-kokoro-tts
    path: dora-kokoro-tts
    inputs:
      text: text-segmenter/text_segment_text  # From text segmenter (participant: text)
    outputs:
      - audio
      - segment_complete  # For backpressure control
      - log
    env:
      # Language and voice settings
      LANGUAGE: zh  # en, zh, ja, ko (auto-detects Chinese characters)
      VOICE: af_heart  # Voice selection (af_heart, bf_emma, am_adam, etc.)
      SPEED: "1.0"  # Speech speed multiplier (0.5-2.0)

      # Logging
      LOG_LEVEL: INFO  # DEBUG, INFO, WARNING, ERROR

  # Simple viewer to see the flow
  - id: viewer
    path: dynamic
    inputs:
      transcription: asr/transcription
      llm_output: maas-client/text
      segment: text-segmenter/text_segment
      speech_started: speech-monitor/speech_started
      speech_ended: speech-monitor/speech_ended
