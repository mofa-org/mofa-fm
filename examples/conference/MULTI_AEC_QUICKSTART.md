# Multi-Party Study System with Human Speaker Quick Start Guide
# å¤šæ–¹å­¦ä¹ ç³»ç»Ÿï¼ˆå«äººç±»è¯´è¯è€…ï¼‰å¿«é€Ÿå…¥é—¨æŒ‡å—

## Prerequisites / å‰ç½®æ¡ä»¶

### System Requirements / ç³»ç»Ÿè¦æ±‚
- Python 3.12+
- Rust (for building Dora components)
- 16GB RAM recommended
- 8-core CPU (4-core minimum)
- macOS / Linux (Windows WSL2)

### API Keys / APIå¯†é’¥
```bash
export OPENAI_API_KEY="your-key-here"
export DEEPSEEK_API_KEY="your-key-here"  
export ALIBABA_CLOUD_API_KEY="your-key-here"
```

## Quick Start / å¿«é€Ÿå¼€å§‹

### 1. Build Dora Components / æ„å»ºDoraç»„ä»¶
```bash
cd /Users/yuechen/home/fresh/dora
cargo build --release -p dora-conference-controller
cargo build --release -p dora-conference-bridge
cargo build --release -p dora-maas-client
```

### 2. Install Python Dependencies / å®‰è£…Pythonä¾èµ–
```bash
pip install -e node-hub/dora-text-segmenter
pip install -e node-hub/dora-primespeech
```

### 3. Download Models / ä¸‹è½½æ¨¡å‹
```bash
# PrimeSpeech TTS models
python examples/model-manager/download_models.py --model primespeech
```

### 4. Start the Dataflow / å¯åŠ¨æ•°æ®æµ

#### Option A: Full System with Audio (Recommended)
```bash
cd examples/conference
dora up
dora start dataflow-study-audio-multi.yml --name study-session
```

#### Option B: Text-Only (No Audio)
```bash
cd examples/conference
dora up
dora start dataflow-study-sequential.yml --name study-session
```

### 5. Launch Dynamic Components / å¯åŠ¨åŠ¨æ€ç»„ä»¶

The dataflow requires several dynamic Python nodes to be started manually:

#### Terminal 1: Study Monitor (TUI)
```bash
cd examples/conference
python debate_monitor.py
```
**Purpose**: Interactive terminal UI for monitoring and controlling the study session
- View real-time participant responses
- See audio buffer status
- Control session flow (pause/resume/reset)

#### Terminal 2: Viewer (Logging)
```bash
cd examples/conference
python debate_viewer.py
```
**Purpose**: Comprehensive logging display
- All component logs in one view
- Status updates from bridges, controller, LLMs
- Debug information for troubleshooting

#### Terminal 3: Audio Player (For Audio Mode)
```bash
cd examples/conference
python audio_player.py --buffer-seconds 30
```
**Purpose**: Multi-participant audio playback
- Plays synthesized speech from all 3 participants
- Manages audio buffer and backpressure (30 seconds buffer)
- Sends completion signals to segmenter

**Parameters**:
- `--buffer-seconds 30` - Audio buffer size (default: 30 seconds)
  - Increase (e.g., 60) if experiencing buffer overflow
  - Decrease (e.g., 15) for lower latency with risk of underflow

#### Terminal 4: MAC-AEC Segmentation (For Human Input)
```bash
cd examples/mac-aec-chat
python mac_aec_simple_segmentation.py
```
**Purpose**: Human speaker input processing
- Captures microphone input with echo cancellation
- Performs speech recognition (ASR)
- Sends transcribed text to controller

### 6. Start the Study Session / å¼€å§‹å­¦ä¹ ä¼šè¯

Once all dynamic components are running, initiate the study session:

#### Using Study Monitor (debate_monitor.py):

1. **The monitor displays a text input area at the bottom**

2. **Type your initial prompt/question**, for example:
   ```
   è¯·è§£é‡Šé‡å­çº ç¼ çš„åŸºæœ¬åŸç†å’Œåº”ç”¨
   (Please explain the basic principles and applications of quantum entanglement)
   ```

3. **Press Enter or click "Send" to submit**

4. **The system will:**
   - Send your prompt to the Tutor (first speaker)
   - Tutor generates response
   - Student1 responds to Tutor
   - Student2 responds to both
   - Audio plays through speakers (if audio mode enabled)

5. **Monitor the conversation in the TUI:**
   - Top panels show participant responses in real-time
   - Bottom panel shows audio buffer status
   - Status indicators show which participant is currently speaking

#### Using Human Voice Input (with MAC-AEC):

1. **Ensure mac_aec_simple_segmentation.py is running**

2. **Speak into your microphone**:
   - The system automatically detects speech
   - Applies echo cancellation to remove speaker feedback
   - Transcribes your speech to text
   - Sends to controller as human input

3. **The system will:**
   - Interrupt any ongoing AI conversation
   - Reset to a new round with incremented question_id
   - Start fresh discussion based on your question

### 7. Monitor and Control / ç›‘æ§å’Œæ§åˆ¶

#### Study Monitor Controls:

**Keyboard Shortcuts**:
- `Ctrl+C` - Stop monitoring (graceful exit)
- `Ctrl+R` - Reset current session
- `Space` - Pause/Resume audio playback
- `â†‘/â†“` - Scroll through conversation history

**Visual Indicators**:
```
â”Œâ”€ Student1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [ACTIVE] Generating response...    â”‚
â”‚ Text appears here as it streams... â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ Audio Buffer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [45.2%] NORMAL â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Viewer Log Categories:

The viewer shows color-coded logs:
- ğŸ”µ **INFO** - Normal operation events
- ğŸŸ¡ **DEBUG** - Detailed processing information
- ğŸ”´ **ERROR** - Issues requiring attention
- ğŸŸ¢ **STATUS** - Component state changes

### 8. Interact with the System / ä¸ç³»ç»Ÿäº¤äº’

#### Text Input (via Study Monitor):

**Single-Turn Questions**:
```
Q: ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ
(What is machine learning?)
```

**Multi-Part Discussions**:
```
Q: è®¨è®ºäººå·¥æ™ºèƒ½çš„ä¼¦ç†é—®é¢˜ï¼Œç‰¹åˆ«å…³æ³¨éšç§å’Œåè§ã€‚
(Discuss the ethical issues of AI, focusing on privacy and bias.)
```

**Follow-Up Questions**:
```
Q: åŸºäºå‰é¢çš„è®¨è®ºï¼Œå¦‚ä½•è§£å†³æ•°æ®åè§é—®é¢˜ï¼Ÿ
(Based on the previous discussion, how to solve data bias issues?)
```

#### Voice Input (via MAC-AEC):

**Natural Speech**:
- Simply speak naturally into your microphone
- Pause briefly between sentences for better recognition
- The system handles echo cancellation automatically

**Interrupt Capability**:
- Speak anytime during AI responses to interrupt
- System resets and starts new round with your input
- Previous conversation context is preserved

### 9. Stop the System / åœæ­¢ç³»ç»Ÿ

#### Graceful Shutdown Sequence:

1. **Stop dynamic components** (in reverse order):
   ```bash
   # In each terminal, press Ctrl+C:
   # Terminal 4: mac_aec_simple_segmentation.py
   # Terminal 3: audio_player.py
   # Terminal 2: debate_viewer.py
   # Terminal 1: debate_monitor.py
   ```

2. **Stop the dataflow**:
   ```bash
   dora destroy
   ```

3. **Stop the daemon**:
   ```bash
   dora down
   ```

#### Quick Stop (If Needed):
```bash
# Kill all dora processes
pkill -9 -f dora

# Clean up
dora down
```

## System Components / ç³»ç»Ÿç»„ä»¶

```
Human â†’ MAC-AEC â†’ ASR â†’ Controller â†’ Bridges â†’ LLMs â†’ Segmenter â†’ TTS â†’ Audio Player â†’ Speakers
äººç±» â†’ å›å£°æ¶ˆé™¤ â†’ è¯­éŸ³è¯†åˆ« â†’ æ§åˆ¶å™¨ â†’ æ¡¥æ¥å™¨ â†’ LLM â†’ åˆ†å‰²å™¨ â†’ TTS â†’ éŸ³é¢‘æ’­æ”¾å™¨ â†’ æ‰¬å£°å™¨
```

## Configuration Files / é…ç½®æ–‡ä»¶

| File | Purpose |
|------|---------|
| `dataflow-study-multi-aec.yml` | Main dataflow configuration / ä¸»æ•°æ®æµé…ç½® |
| `study_config_maas_student1.toml` | Student1 LLM configuration / å­¦ç”Ÿ1é…ç½® |
| `study_config_maas_student2.toml` | Student2 LLM configuration / å­¦ç”Ÿ2é…ç½® |
| `study_config_maas_tutor.toml` | Tutor LLM configuration / å¯¼å¸ˆé…ç½® |

## Common Issues / å¸¸è§é—®é¢˜

### Audio Not Playing / éŸ³é¢‘ä¸æ’­æ”¾
```bash
# Check audio device
python -c "import sounddevice as sd; print(sd.query_devices())"

# Restart audio-player
dora destroy && dora start dataflow-study-multi-aec.yml
```

### LLM Timeout / LLMè¶…æ—¶
- Check API keys / æ£€æŸ¥APIå¯†é’¥
- Check network connection / æ£€æŸ¥ç½‘ç»œè¿æ¥
- Increase timeout in config / å¢åŠ é…ç½®ä¸­çš„è¶…æ—¶æ—¶é—´

### Buffer Overflow / ç¼“å†²åŒºæº¢å‡º
- Lower `AUDIO_BUFFER_THRESHOLD` from 30 to 20
- Increase `buffer_seconds` from 30 to 60

## Next Steps / ä¸‹ä¸€æ­¥

1. Read full architecture: `MULTI_AEC_ARCHITECTURE.md`
2. Customize personas in `study_config_maas_*.toml`
3. Adjust speaking order in `DORA_POLICY_PATTERN`
4. Tune audio parameters for your hardware

## Support / æ”¯æŒ

- GitHub Issues: https://github.com/kippalbot/dora/issues
- Documentation: See `MULTI_AEC_ARCHITECTURE.md`
