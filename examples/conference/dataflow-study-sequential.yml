# Conference Study Session Example - Sequential Policy (3-Bridge Architecture)
#
# Implements a 3-person study session using conference controller and bridge
# with sequential policy: student1 â†’ student2 â†’ tutor â†’ repeat
#
# Follows llm-client/dataflow-maas-debate.yml pattern with 3 bridges:
# - bridge-to-tutor: forwards to tutor (inputs: student1, student2)
# - bridge-to-student2: forwards to student2 (inputs: student1, tutor)
# - bridge-to-student1: forwards to student1 (inputs: student2, tutor)
#
# Reuses components from llm-client:
# - dora-maas-client (via maas configs)
# - debate-monitor (3-panel TUI) - renamed to study-monitor
# - viewer (log monitoring)

nodes:
  # ============ Study Participants (MaaS) ============
  # Same as dataflow-maas-debate.yml - uses path: not operator:

  - id: student1
    path: ../../target/release/dora-maas-client
    inputs:
      text: bridge-to-student1/text
      control: conference-controller/llm_control
    outputs:
      - text
      - status
      - log
    env:
      MAAS_CONFIG_PATH: study_config_maas_student1.toml
      ALIBABA_CLOUD_API_KEY: ${ALIBABA_CLOUD_API_KEY:-}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      DEEPSEEK_API_KEY: ${DEEPSEEK_API_KEY:-}
      LOG_LEVEL: INFO

  - id: student2
    path: ../../target/release/dora-maas-client
    inputs:
      text: bridge-to-student2/text
      control: conference-controller/llm_control
    outputs:
      - text
      - status
      - log
    env:
      MAAS_CONFIG_PATH: study_config_maas_student2.toml
      ALIBABA_CLOUD_API_KEY: ${ALIBABA_CLOUD_API_KEY:-}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      DEEPSEEK_API_KEY: ${DEEPSEEK_API_KEY:-}
      LOG_LEVEL: INFO

  - id: tutor
    path: ../../target/release/dora-maas-client
    inputs:
      text: bridge-to-tutor/text
      control: conference-controller/judge_prompt # User prompts from study-monitor
    outputs:
      - text
      - status
      - log
    env:
      MAAS_CONFIG_PATH: study_config_maas_tutor.toml
      ALIBABA_CLOUD_API_KEY: ${ALIBABA_CLOUD_API_KEY:-}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      DEEPSEEK_API_KEY: ${DEEPSEEK_API_KEY:-}
      LOG_LEVEL: INFO

  # ============ 3 Conference Bridges (Switch) ============
  # Each bridge forwards to one participant, controlled by conference-controller
  # Defaults to PAUSED state, only forwards on explicit "resume" from controller
  # Each bridge receives from the other two participants (matching llm-client pattern)

  # Bridge 1: Student1 + Student2 â†’ Tutor
  # Listens to controller for when tutor should speak
  - id: bridge-to-tutor
    path: ../../target/release/dora-conference-bridge
    env:
      LOG_LEVEL: INFO
      STREAMING_PORTS: student1,tutor,student2
      ERROR_MESSAGE_TEMPLATE: "[{participant} is experiencing technical difficulties. We will proceed without their response.]"
      DORA_STUDY_MODE: "true"
    inputs:
      # Other participants' outputs
      student1: student1/text
      student2: student2/text
      # Controller tells bridge when to forward
      control:
        source: conference-controller/control_judge
        queue_size: 10
    outputs:
      - text # â†’ Tutor
      - status # â†’ "forwarded" status
      - log # â†’ Debug logs

  # Bridge 2: Student1 + Tutor â†’ Student2
  # Listens to controller for when student2 should speak
  - id: bridge-to-student2
    path: ../../target/release/dora-conference-bridge
    env:
      LOG_LEVEL: INFO
      STREAMING_PORTS: student1,tutor,student2
      ERROR_MESSAGE_TEMPLATE: "[{participant} is experiencing technical difficulties. We will proceed without their response.]"
      DORA_STUDY_MODE: "true"
    inputs:
      # Other participants' outputs
      student1: student1/text
      tutor: tutor/text
      # Controller tells bridge when to forward
      control:
        source: conference-controller/control_llm2
        queue_size: 10
    outputs:
      - text # â†’ Student2
      - status # â†’ "forwarded" status
      - log # â†’ Debug logs

  # Bridge 3: Student2 + Tutor â†’ Student1
  # Listens to controller for when student1 should speak
  - id: bridge-to-student1
    path: ../../target/release/dora-conference-bridge
    env:
      LOG_LEVEL: INFO
      STREAMING_PORTS: student1,tutor,student2
      ERROR_MESSAGE_TEMPLATE: "[{participant} is experiencing technical difficulties. We will proceed without their response.]"
      DORA_STUDY_MODE: "true"
    inputs:
      # Other participants' outputs
      student2: student2/text
      tutor: tutor/text
      # Controller tells bridge when to forward
      control:
        source: conference-controller/control_llm1
        queue_size: 10
    outputs:
      - text # â†’ Student1
      - status # â†’ "forwarded" status
      - log # â†’ Debug logs

  # ============ Conference Controller (Brain) ============
  # Controls speaking order: student2 â†’ student1 â†’ tutor â†’ repeat
  # Uses sequential policy from env variable
  # Sends "resume" to appropriate bridge based on policy

  - id: conference-controller
    path: ../../target/release/dora-conference-controller
    env:
      # ðŸŽ¯ Sequential policy: fixed speaking order
      #DORA_POLICY_PATTERN: "[student2 â†’ student1 â†’ tutor]"
      DORA_POLICY_PATTERN: "[(tutor, *), (student2, 2), (student1, 1)]"
    inputs:
      # When any participant speaks, controller updates policy
      student1: student1/text
      student2: student2/text
      tutor: tutor/text
      # Control from study-monitor UI
      control: debate-monitor/control
    outputs:
      - control_judge # â†’ "resume" to bridge-to-tutor
      - control_llm2 # â†’ "resume" to bridge-to-student2
      - control_llm1 # â†’ "resume" to bridge-to-student1
      - llm_control # â†’ "reset/cancel" to Student1 and Student2
      - judge_prompt # â†’ User prompts and reset/cancel to tutor
      - status # â†’ Policy statistics

  # ============ Study Monitor (TUI) ============
  # Real-time 3-panel terminal UI
  # Reused from llm-client/debate_monitor.py - use path: dynamic!

  - id: debate-monitor
    path: dynamic
    env:
      DORA_STUDY_MODE: "true"
    inputs:
      # Student1 panel
      llm1_text: student1/text
      llm1_status: student1/status
      llm1_prompt: bridge-to-student1/text

      # Student2 panel
      llm2_text: student2/text
      llm2_status: student2/status
      llm2_prompt: bridge-to-student2/text

      # Tutor panel
      judge_text: tutor/text
      judge_status: tutor/status
      judge_prompt: bridge-to-tutor/text
    outputs:
      - control # â†’ To conference-controller for reset and other commands

  # ============ Viewer (Logging) ============
  # Log and event monitoring
  # Reused from llm-client/viewer.py - use path: dynamic!

  - id: viewer
    path: dynamic
    inputs:
      # Student1 logs
      llm1_log: student1/log
      llm1_status: student1/status
      llm1_text: student1/text

      # Student2 logs
      llm2_log: student2/log
      llm2_status: student2/status
      llm2_text: student2/text

      # Tutor logs
      judge_log: tutor/log
      judge_status: tutor/status
      judge_text: tutor/text

      # Bridge logs
      bridge1_log: bridge-to-tutor/log
      bridge1_status: bridge-to-tutor/status
      bridge1_text: bridge-to-tutor/text
      bridge2_log: bridge-to-student2/log
      bridge2_status: bridge-to-student2/status
      bridge2_text: bridge-to-student2/text
      bridge3_log: bridge-to-student1/log
      bridge3_status: bridge-to-student1/status
      bridge3_text: bridge-to-student1/text

      # Controller logs and control commands
      controller_status: conference-controller/status
      controller_log: conference-controller/log
      control_judge: conference-controller/control_judge
      control_llm2: conference-controller/control_llm2
      control_llm1: conference-controller/control_llm1
